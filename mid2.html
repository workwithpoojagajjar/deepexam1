Que1: Using Keras's Functional API, write the code for a convolutional neural network corresponding to the following information: the network uses the 'Conv/Con/Max Pooling' block pattern, contains 3 blocks, the number of
filters follows a [ 32, 256, 512) pattern from block to block, and the classifier portion has 1 layer(s) with activation(s) = ReLU, and [128] neurons, respectively. The output layer has 3 neuron(s) and should have an activation
suitable to a classification problem. All convolutional layers have activation - ReLU, filter size = (3, 3) and padding - valid, while the pooling layers have a window of size - (3, 3); both types of layers have typical values for
the stride. The input data has shape = (32, 32, 1). All hyperparameters noted in the question should be included explicitly in your code. Your code only needs to create the model, that is, no imports, no data, no compile.
no fit.

Answer1:

from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten
from tensorflow.keras.models import Model

# Input layer
input_layer = Input(shape=(32, 32, 1))

# Block 1
x = Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='valid', strides=(1, 1))(input_layer)
x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)

# Block 2
x = Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='valid', strides=(1, 1))(x)
x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)

# Block 3
x = Conv2D(filters=512, kernel_size=(3, 3), activation='relu', padding='valid', strides=(1, 1))(x)
x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)

# Flatten and classifier portion
x = Flatten()(x)
x = Dense(128, activation='relu')(x)

# Output layer for a classification problem with 3 classes
output_layer = Dense(3, activation='softmax')(x)

# Create the model
model = Model(inputs=input_layer, outputs=output_layer)


Que2: For the input array x = p.array([[ 6, 2, 9, 5, 2, 7), [10, 0, 1, 6, 10, 8], [ 2, 9, 0, 0, 10, 8), [ 3, 2, 2, 7, 0, 3], [10, 9, 4, 1, 6, 6], [10, 7, 8, 7, 4, 10]]), filter f = p.array/(-1, -1, 11, [ 3, -2, 01. (-1, 0, -31), padding = valid, and strides = 1,
what is the convolutional output for the [0, 0] element of the output array?

﻿﻿6.0
﻿﻿29.0
0-41.0

Ans2: 29.0

Que3: You have imported a pretrained model as ResNet50. This pretrained model only contains the convolution portion, and its final layer is a average pooling layer. Using Keras's functional API, create a model that uses this pretrained model and has a classifier with one hidden layer with 64 neurons with activation sigmoid and an output layer with 10 neurons and an activation suitable for classification. There should be a layer that assures that the pixel values processed by the network have values in the range 0 to 1. The network should be able to process images with dimensions (32, 32, 3). (No preprocessing layer is required.)

Ans3: 
from tensorflow.keras.layers import Input, Rescaling, Dense, Flatten
from tensorflow.keras.models import Model
from tensorflow.keras.applications import ResNet50

# Input layer
input_layer = Input(shape=(32, 32, 3))

# Rescaling layer to ensure pixel values are in the range [0, 1]
x = Rescaling(scale=1.0 / 255)(input_layer)

# Load the pretrained ResNet50 model (only the convolution portion, excluding the top classifier layers)
# We set include_top=False to exclude the fully connected layers
# Set pooling to 'avg' to add a global average pooling layer at the end of the ResNet model
pretrained_model = ResNet50(include_top=False, pooling='avg', input_shape=(32, 32, 3))
x = pretrained_model(x)

# Flattening layer is not needed as pooling='avg' outputs a 1D tensor

# Classifier portion
x = Dense(64, activation='sigmoid')(x)
output_layer = Dense(10, activation='softmax')(x)

# Create the final model
model = Model(inputs=input_layer, outputs=output_layer)


Que4: If your model starts training but can't beat a baseline, the problem is most likely:
﻿﻿the learning rate is not appropriate that an incorrect type of pooling layer was used
﻿﻿the data, or the model architecture

Ans4: The data, or the model architecture

Que5: Which method will not effect the height and width of your data:
﻿﻿a Conv2D layer with strides set to a value greater than 1
﻿﻿using a customized activation function in your convolutional layer
O using a typical pooling layer

Ans5: Using a customized activation function in your convolutional layer

que6: If your model doesn't start training the most likely problem is:
﻿﻿the learning rate is not appropriate
﻿﻿that an incorrect weight initialization was used
O the optimizer was not chosen properly

Ans6: An incorrect weight initialization was used


Que7: Data augmentation means you:
© modify your existing data to help expose the model to more aspects of the data so it can generalize better
﻿﻿use a dataset that is different from your original dataset so your model can learn better patterns
﻿﻿add new images to your dataset to reduce overfitting

Ans7: Modify your existing data to help expose the model to more aspects of the data so it can generalize better.

Que8:What two properties do convolutional neural networks have that make them much more useful for images than fully-connected networks?
• parameter sharing/global pattern matching
O parameter sharing/local pattern matthing
• parameter optimization/local pattern matching

Ans8: Parameter sharing / local pattern matching

Que9: For the input array x = np.array([[ 9., 8., 2., 14.], [ 4., 7., 2., 6.], [20., 2., 5., 27.J, [4., 24., 10., 10.]]), pool size - (2, 2), and strides = 2, what is the output of applying Average Pooling;
﻿﻿[[ 4.5, 4., 7. J. [10., 3.5, 13.5), [12., 12., 13.5)]
﻿﻿[ 7., 6. ). [12.5, 13. ]J|
﻿﻿[3., 2.75]. [2.75, 1.75])

Ans9: [ 
7
12.5
6
13
​
 ]

Que10: How many trainable parameters in total do the following layers have: a Conv2D(32, (5, 5), activation='sigmoid) layer followed by a Conv2D(64, (5, 5), activation= sigmoid) layer, where the input to the first Conv2d0 layer has dimesions (90, 90, 16)?
﻿﻿64096
﻿﻿64000
О 129600

Ans10: 64096

Que11: You have imported the convolution portion of a pretrained model and its layers are stored as model=[Layer('Conv2D_block_1'), Layer ('Conv2D_block_1'), Layer(MaxPooling_block_1'), Layer('Conv2D _block _2).
Layer(ConvD _block_2'), Layer("MaxPooling_block_2"), Layer('Conv2D_block_3'), Layer('Conv2D_block_3'), Layer(MaxPooling_block _3'), Layer('Conv2D _block_4"), Layer('Conv2D_block 4", Layer(MaxPooling block_4),
Layer(Conv2D_block_5'), Layer('Conv2D_block_5'), Layer(MaxPooling block_5'), Layer(Conv2D_block_6), Layer('Conv2D_block_6), Layer(MaxPooling_block _6')]. Write code that will make only the layers in the last block trainable. (See provided class definition for Layer.)

Ans11: # Assuming model is a list of layers as described
class Layer:
    def __init__(self, name):
        self.name = name
        self.trainable = True  # Default is trainable

# Example model definition
model = [
    Layer('Conv2D_block_1'), Layer('Conv2D_block_1'), Layer('MaxPooling_block_1'),
    Layer('Conv2D_block_2'), Layer('Conv2D_block_2'), Layer('MaxPooling_block_2'),
    Layer('Conv2D_block_3'), Layer('Conv2D_block_3'), Layer('MaxPooling_block_3'),
    Layer('Conv2D_block_4'), Layer('Conv2D_block_4'), Layer('MaxPooling_block_4'),
    Layer('Conv2D_block_5'), Layer('Conv2D_block_5'), Layer('MaxPooling_block_5'),
    Layer('Conv2D_block_6'), Layer('Conv2D_block_6'), Layer('MaxPooling_block_6')
]

# Determine the layers in the last block
last_block_start_index = len(model) - 6  # Assuming each block has 3 layers (Conv2D, Conv2D, MaxPooling)
last_block_layers = model[last_block_start_index:]

# Set all layers in the model to non-trainable
for layer in model:
    layer.trainable = False

# Set only the layers in the last block to trainable
for layer in last_block_layers:
    layer.trainable = True

# Output the trainable status of each layer for verification
for layer in model:
    print(f'Layer: {layer.name}, Trainable: {layer.trainable}')


Explanation:
Layer Class: A simple class to represent layers with a name and a trainable attribute.
Model Definition: A list of layers representing the structure of the pretrained model.
Last Block Identification: The code identifies the last block by slicing the model list.
Trainability Setting: It first sets all layers to trainable = False, and then sets the layers in the last block to trainable = True.
Verification: The code prints the trainable status of each layer for confirmation.
---------------------------------------------------------------------------------------------------------------------------------------
que12: How many trainable parameters in total do the following layers have: a Conv2D(128, (5, 5), activation 'tanh') layer followed by a Conv2D(32, (5, 5), activation- tanh) layer, where the input to the first Com/2d0 layer has
dimesions (224, 224, 16)2
﻿﻿802816
﻿﻿153600|
﻿﻿153760|

Ans12: 153760

que13: What do we mean by the **receptive field** of a filter in a convolutional neural network?

Ans13:
##In a CNN, the receptive field of a filter refers to the specific region of the input image that influences a particular neuron in the output.

Initially, each filter covers a small, localized part of the input, capturing fine details like edges. As the network goes deeper, the effective receptive field increases, allowing neurons in deeper layers to "see" larger portions of the image and detect more complex patterns. The receptive field size depends on the filter size, strides, and pooling across layers and is key to capturing both local and global features in the data.

What 2 properties do convolutional neural networks have that make them much more useful for images than fully-connected networks?

Ans: ##Convolutional Neural Networks (CNNs) are particularly well-suited for image data due to these two key properties:

##1. Spatial Hierarchy and Local Connectivity ##2. Parameter Sharing

Spatial Hierarchy and Local Connectivity: CNNs use convolutional layers where each filter (or kernel) connects to a local region of the input image, capturing spatial hierarchies. This local connectivity enables the model to detect edges, textures, and patterns in small regions and then combine them at deeper layers to recognize more complex structures like shapes or objects.

Parameter Sharing: In CNNs, filters are shared across the image, meaning the same filter scans the entire input image to identify the same feature (like an edge or texture) across different locations. This significantly reduces the number of parameters compared to fully connected networks, making CNNs more efficient and less prone to overfitting on image data.

Explain/use padding.

Ans: ##Padding in CNNs is a technique where additional pixels are added around the edges of an input image before applying a convolutional layer.

Padding helps control the spatial dimensions of the output feature maps and allows the network to preserve more information at the edges of the image.

Why Padding is Important Maintain Spatial Dimensions: Without padding, the spatial dimensions of the image reduce with each convolution.

##Types of Padding:

Valid Padding (No Padding): No extra pixels are added, so the output shrinks with each convolution. This can be useful when reducing spatial dimensions is desired.

Same Padding: Pixels are added to the input’s edges to ensure that the output dimensions match the input dimensions (if the stride is 1). This is commonly used to maintain image size through multiple layers.

Explain/use strides.

Ans: ##Gives info about how filters are moved across the input matrix.

Impact of Strides Output Size: Larger strides lead to smaller output feature maps, as fewer positions are covered during convolution. This can help reduce computational load and the number of parameters.

Detail and Resolution: Higher stride values reduce the resolution of the feature map, which might cause some finer details to be lost. Lower strides capture finer details but increase computation and output size.

What is the purpose of a pooling layer?

Ans: To reduce the height and width sequentially. Pooling is a form of downsampling.

What is the difference between a parameter and a hyperparameter?

Ans: Parameters are learned from the data during training, while hyperparameters are set before training and control the learning process.

Parameters directly affect the predictions, as they are part of the model itself, whereas hyperparameters impact the model's training behavior and effectiveness but aren’t part of the model’s structure.

What are training, validation, and test datasets used for?

Ans: The training dataset is used to train the model, allowing it to learn patterns and relationships within the data.

The validation dataset is used for tuning the model and adjusting hyperparameters.

The test dataset is used solely to evaluate the final performance of the model after training and tuning are complete.

What is a baseline and how is it used?

Ans: A baseline in machine learning is a simple model or metric that serves as a reference point for evaluating the performance of more complex models. It provides a minimum standard of performance that a new model should at least meet or exceed.

What are the first 2 goals we should have when creating a deep learning model?

Ans:

Create an overfit model.
Generalize the model to reduce loss.
What are some ways to deal with overfitting?

Ans:

Simplifying the Model
Reducing Epochs
Batch Normalization
Regularization Techniques
Increasing Training Data
What are some common problems when training a model and how can they be overcome?

Ans:

Overfitting Problem: The model performs well on the training data but poorly on validation/test data. Solutions: Use regularization techniques (L1, L2). Implement dropout in neural networks. Simplify the model architecture. Increase training data or apply data augmentation.

Underfitting Problem: The model performs poorly on both training and validation data, failing to capture the underlying patterns. Solutions: Increase model complexity (more layers or neurons). Reduce regularization if it’s too strong. Ensure sufficient training time (increase epochs). Improve feature selection or engineering.

Poor Generalization Problem: The model does not perform well on unseen data. Solutions: Use k-fold cross-validation to assess model robustness. Ensure that the training data is representative of the real-world scenario. Apply techniques like ensemble learning.

Long Training Times Problem: Training the model takes an excessive amount of time, making experimentation difficult. Solutions: Use hardware acceleration (GPUs/TPUs). Optimize model architecture for efficiency. Utilize batch processing to speed up computation. Reduce the complexity of the model.

Imbalanced Dataset Problem: One class is overrepresented compared to others, leading to biased predictions. Solutions: Use techniques like oversampling, undersampling, or SMOTE (Synthetic Minority Over-sampling Technique). Implement cost-sensitive learning by assigning higher costs to misclassifying the minority class. Use ensemble methods that are robust to class imbalance.

Transfer learning/Fine-tuning

what is it? why do we do it?
import pre-trained model
build a new model using all or part of pre-trained model
freeze parameters
Ans:

##What is it? ##Transfer Learning is a machine learning technique where a pre-trained model, developed on a large dataset, is adapted for a specific task. Instead of training a model from scratch, transfer learning leverages the learned features from the pre-trained model, which often results in better performance, especially when the target dataset is small.

##Fine-Tuning refers to the process of making small adjustments to the pre-trained model on the new dataset to improve performance. This often involves retraining some layers of the model while keeping others fixed.

##Why do we do it? ##Reduced Training Time, Improved Performance, Limited Data.

Reduced Training Time: Fine-tuning a pre-trained model can significantly reduce the time and computational resources needed for training.

Improved Performance: Pre-trained models often have learned useful representations that can be applied to similar tasks, resulting in higher accuracy.

Limited Data: Transfer learning is particularly useful when the target task has a limited amount of labeled data, as the model can leverage the knowledge gained from the larger dataset.

##Steps in Transfer Learning and Fine-Tuning: ##Import Pre-trained Model, Build a New Model Using All or Part of the Pre-trained Model, Freeze Parameters.

Import Pre-trained Model: You can use popular pre-trained models from libraries like TensorFlow (Keras) or PyTorch.

Build a New Model Using All or Part of the Pre-trained Model: You can either use the entire model or take specific layers from the pre-trained model to build a new architecture.

Freeze Parameters: Freezing parameters involves setting some layers of the pre-trained model to non-trainable so that their weights do not get updated during training. This is typically done for the earlier layers, which capture general features.

Data augmentation

what is it? why do we do it?
how to create a data augmentation layer
Ans:

What is it?
##Data Augmentation is a technique used in machine learning, to artificially increase the size of a training dataset by creating modified versions of existing data points. This can include transformations such as rotations, translations, flips, zooms, and changes in brightness or contrast. The idea is to introduce variability in the training data without needing to collect additional data.

Why do we do it?
Improve Generalization, Increase Robustness, Utilize Limited Data
Improve Generalization: By providing a more diverse set of training examples, data augmentation helps models learn to generalize better, reducing the risk of overfitting to the training data. Increase Robustness: Augmented data can make models more resilient to variations and noise in real-world data. Utilize Limited Data: In scenarios where collecting more data is expensive or impractical, data augmentation allows for better performance by effectively expanding the dataset.

##How to Create a Data Augmentation Layer: ##In libraries like TensorFlow (Keras) and PyTorch, you can easily create a data augmentation layer.

​
headers = {
    'Cache-Control': 'no-cache',  # Instructs the browser and server not to cache
    'Pragma': 'no-cache'          # HTTP/1.0 compatibility; often used with Cache-Control
}